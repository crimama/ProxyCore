{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from arguments import parser \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "import os \n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' \n",
    "cfg = OmegaConf.load('results/PatchCore/MVTecAD/screw/baseline-identity-sampling_ratio_0.1-anomaly_ratio_0.0/seed_0/configs.yaml')\n",
    "\n",
    "# model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "#         backbone = cfg.MODEL.backbone,\n",
    "#         **cfg.MODEL.params\n",
    "#         )\n",
    "# # model.load_state_dict(\n",
    "# #         torch.load('results/ProxyCoreBase/MVTecAD/screw/baseline-anomaly_ratio_0.0/seed_0/model_best.pt')\n",
    "# # )\n",
    "# model.to('cuda')\n",
    "\n",
    "trainset, testset = create_dataset(\n",
    "    dataset_name  = cfg.DATASET.dataset_name,\n",
    "    datadir       = cfg.DATASET.datadir,\n",
    "    class_name    = cfg.DATASET.class_name,\n",
    "    img_size      = cfg.DATASET.img_size,\n",
    "    mean          = cfg.DATASET.mean,\n",
    "    std           = cfg.DATASET.std,\n",
    "    aug_info      = cfg.DATASET.aug_info,\n",
    "    **cfg.DATASET.get('params',{})\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "testloader = DataLoader(\n",
    "        dataset     = testset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = False \n",
    "    )    \n",
    "\n",
    "# train_featureloader = model.get_feature_loader(trainloader)\n",
    "# test_featureloader = model.get_feature_loader(testloader)\n",
    "\n",
    "# self = model.core\n",
    "\n",
    "# import timm \n",
    "# import torch.nn.functional as F \n",
    "# vit = timm.create_model('vit_small_patch16_224_in21k',pretrained=True)\n",
    "# vit.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PatchCore\n",
    "import sys \n",
    "sys.path.append('/Volume/VAD/UAADF/softpatch/src')\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import timm \n",
    "from models.softpatch.src import common, sampler, multi_variate_gaussian, backbones\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest    \n",
    "from skimage.filters import threshold_otsu, threshold_mean, threshold_li, threshold_yen, threshold_triangle\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def get_sampler(sampler_name, sampling_ratio, device):\n",
    "    if sampler_name == \"identity\":\n",
    "        return sampler.IdentitySampler()\n",
    "    elif sampler_name == \"greedy_coreset\":\n",
    "        return sampler.GreedyCoresetSampler(sampling_ratio, device)\n",
    "    elif sampler_name == \"approx_greedy_coreset\":\n",
    "        return sampler.ApproximateGreedyCoresetSampler(sampling_ratio, device)\n",
    "    \n",
    "class MaskGenerator:\n",
    "    def __init__(self, input_size=192, mask_patch_size=32, model_patch_size=4, mask_ratio=0.6):\n",
    "        self.input_size = input_size\n",
    "        self.mask_patch_size = mask_patch_size\n",
    "        self.model_patch_size = model_patch_size\n",
    "        self.mask_ratio = mask_ratio\n",
    "        \n",
    "        assert self.input_size % self.mask_patch_size == 0\n",
    "        assert self.mask_patch_size % self.model_patch_size == 0\n",
    "        \n",
    "        self.rand_size = self.input_size // self.mask_patch_size\n",
    "        self.scale = self.mask_patch_size // self.model_patch_size\n",
    "        \n",
    "        self.token_count = self.rand_size ** 2\n",
    "        self.mask_count = int(np.ceil(self.token_count * self.mask_ratio))\n",
    "        \n",
    "    def __call__(self):\n",
    "        mask_idx = np.random.permutation(self.token_count)[:self.mask_count]\n",
    "        mask = np.zeros(self.token_count, dtype=int)\n",
    "        mask[mask_idx] = 1\n",
    "        \n",
    "        mask = mask.reshape((self.rand_size, self.rand_size))\n",
    "        mask = mask.repeat(self.scale, axis=0).repeat(self.scale, axis=1)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "class MIMCore(PatchCore):\n",
    "    def __init__(self, encoder, backbone, faiss_on_gpu, faiss_num_workers, \n",
    "                 sampling_ratio, device, input_shape, threshold='quant15', weight_method='identity'):\n",
    "        super(MIMCore,self).__init__(backbone,faiss_on_gpu,faiss_num_workers,sampling_ratio,device,input_shape,\n",
    "                                     threshold, weight_method)\n",
    "        \n",
    "        self.load(\n",
    "            backbone = timm.create_model(backbone, pretrained=True),\n",
    "            device         = device,\n",
    "            input_shape    = input_shape,\n",
    "            nn_method      = common.FaissNN(faiss_on_gpu,faiss_num_workers,int(device.strip('cuda:'))),\n",
    "            featuresampler = get_sampler(sampler_name = 'approx_greedy_coreset',\n",
    "                                              sampling_ratio = sampling_ratio,\n",
    "                                              device = device),\n",
    "            threshold = threshold,\n",
    "            weight_method = weight_method\n",
    "            )\n",
    "        \n",
    "        self.reducing_mapper = torch.nn.Linear(1024,384,bias=False)\n",
    "        self.mask_generator = MaskGenerator(\n",
    "                                                    input_size = 224,\n",
    "                                                    mask_patch_size = 32,\n",
    "                                                    mask_ratio = 0.6,\n",
    "                                                    model_patch_size=16\n",
    "                                                )\n",
    "        self.encoder = encoder \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _embed(self, images):\n",
    "        with torch.no_grad():\n",
    "            features = self.forward_modules['feature_aggregator'](images)\n",
    "\n",
    "        features = [features[layer] for layer in self.layers_to_extract_from]\n",
    "        features = [self.patch_maker.patchify(x, return_spatial_info=True) for x in features]\n",
    "\n",
    "        patch_shapes = [x[1] for x in features] # [[28, 28], [14, 14]]\n",
    "        features = [x[0] for x in features]\n",
    "        ref_num_patches = patch_shapes[1] # [14,14]\n",
    "\n",
    "        for i in range(0, len(features)):\n",
    "            _features = features[i]\n",
    "            patch_dims = patch_shapes[i]\n",
    "\n",
    "            _features = _features.reshape(\n",
    "                _features.shape[0], patch_dims[0], patch_dims[1], *_features.shape[2:]\n",
    "            )\n",
    "           \n",
    "            _features = _features.permute(0, -3, -2, -1, 1, 2)\n",
    "            perm_base_shape = _features.shape\n",
    "            _features = _features.reshape(-1, *_features.shape[-2:])\n",
    "          \n",
    "            _features = F.interpolate(\n",
    "                        _features.unsqueeze(1),\n",
    "                        size=(ref_num_patches[0], ref_num_patches[1]),\n",
    "                        mode=\"bilinear\",\n",
    "                        align_corners=False,\n",
    "                    )\n",
    "\n",
    "            _features = _features.squeeze(1)\n",
    "            _features = _features.reshape(\n",
    "                        *perm_base_shape[:-2], ref_num_patches[0], ref_num_patches[1]\n",
    "                    )\n",
    "           \n",
    "            _features = _features.permute(0, -2, -1, 1, 2, 3)\n",
    " \n",
    "            _features = _features.reshape(len(_features), -1, *_features.shape[-3:])\n",
    " \n",
    "            \n",
    "            features[i] = _features\n",
    "        features = [x.reshape(-1, *x.shape[-3:]) for x in features]\n",
    "        features = self.forward_modules[\"preprocessing\"](features)\n",
    "        features = self.forward_modules[\"preadapt_aggregator\"](features)\n",
    "        features = features.reshape(-1,196,1024)\n",
    "        return features \n",
    "    \n",
    "    def forward(self, images:torch.Tensor):\n",
    "        features = self._embed(images)\n",
    "        features = self.reducing_mapper(features)\n",
    "        \n",
    "        x = features \n",
    "        B, L, _ = features.shape\n",
    "\n",
    "        mask = torch.Tensor(self.mask_generator().reshape(1,14,14,1)).to('cuda')\n",
    "\n",
    "        mask_token = nn.Parameter(torch.zeros(1,1,384))\n",
    "        mask_token = mask_token.expand(B, L, -1).to('cuda')\n",
    "        w = mask.flatten(1).unsqueeze(-1).type_as(mask_token)\n",
    "        x = x * (1 - w) + mask_token * w\n",
    "\n",
    "        cls_tokens = self.encoder.cls_token.expand(B,-1,-1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = self.encoder.pos_drop(x)\n",
    "        x = self.encoder.blocks(x)\n",
    "        x = self.encoder.norm(x)\n",
    "\n",
    "        output = x[:, 1:]\n",
    "        output = output.reshape(-1,14,14,384)\n",
    "        self.output = output \n",
    "        self.features = features \n",
    "        features = features.reshape(-1,14,14,384)\n",
    "        loss = F.l1_loss(features,output,reduction='none')\n",
    "        loss = (loss * mask).sum() / (mask.sum() + 1e-5) / 3\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "import torch.nn.functional as F \n",
    "encoder = timm.create_model('vit_small_patch16_224_in21k',pretrained=True)\n",
    "encoder.to('cuda')\n",
    "\n",
    "model  = MIMCore(\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        encoder = encoder,\n",
    "        **cfg.MODEL.params\n",
    "        )\n",
    "model.to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator \n",
    "acc = Accelerator() \n",
    "model, optimizer, trainloader,testloader = acc.prepare(model, optimizer, trainloader,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1475.8062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(679.1708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(476.9736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(388.8877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(336.1979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(296.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(268.5957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(258.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(264.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(323.8585, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    for i,(imgs, labels, gts) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if e%10 ==0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] \n",
    "for imgs, labels,gts in trainloader:\n",
    "    with torch.no_grad():\n",
    "        feats = model._embed(imgs)\n",
    "        feats = model.reducing_mapper(feats)\n",
    "        \n",
    "        B, L, _ = feats.shape\n",
    "        \n",
    "        cls_tokens = model.encoder.cls_token.expand(B,-1,-1)\n",
    "        x = torch.cat((cls_tokens, feats), dim=1)\n",
    "        x = model.encoder.pos_drop(x)\n",
    "        x = model.encoder.blocks(x)\n",
    "        x = model.encoder.norm(x)\n",
    "        output = x[:, 1:]\n",
    "        \n",
    "    features.append(output.reshape(-1,384).detach().cpu().numpy())\n",
    "features = np.vstack(features)    \n",
    "sample_features, _ = model.featuresampler.run(features)\n",
    "model.anomaly_scorer.fit(detection_features=[sample_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import MetricCalculator\n",
    "img_level = MetricCalculator(metric_list = ['auroc','average_precision'])\n",
    "pix_level = MetricCalculator(metric_list = ['auroc','average_precision'])\n",
    "\n",
    "    \n",
    "_ = model.forward_modules.eval()\n",
    "for imgs, labels,gts in testloader:\n",
    "    batchsize = imgs.shape[0]\n",
    "    with torch.no_grad():\n",
    "        feats = model._embed(imgs)\n",
    "        feats = model.reducing_mapper(feats)\n",
    "        \n",
    "        B, L, _ = feats.shape\n",
    "        \n",
    "        cls_tokens = model.encoder.cls_token.expand(B,-1,-1)\n",
    "        x = torch.cat((cls_tokens, feats), dim=1)\n",
    "        x = model.encoder.pos_drop(x)\n",
    "        x = model.encoder.blocks(x)\n",
    "        x = model.encoder.norm(x)\n",
    "        output = x[:, 1:]\n",
    "        output = output.reshape(-1,384)\n",
    "        \n",
    "        image_scores, _, _ = model.anomaly_scorer.predict([output.detach().cpu().numpy()])      \n",
    "        # get patch wise anomaly score using image score    \n",
    "        patch_scores = model.patch_maker.unpatch_scores(\n",
    "        image_scores, batchsize=batchsize\n",
    "        ) # Unfold : (B)\n",
    "                \n",
    "        scales = [14,14]\n",
    "        patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1])\n",
    "        masks = model.anomaly_segmentor.convert_to_segmentation(patch_scores) # interpolation : (B,pw,ph) -> (B,W,H)\n",
    "                \n",
    "        score_map = np.concatenate([np.expand_dims(sm,0) for sm in masks])\n",
    "        score_map = np.expand_dims(score_map,1)\n",
    "\n",
    "        # get image wise anomaly score \n",
    "        image_scores = model.patch_maker.unpatch_scores(\n",
    "        image_scores, batchsize=batchsize\n",
    "        )\n",
    "        image_scores = image_scores.reshape(*image_scores.shape[:2], -1)\n",
    "        image_scores = model.patch_maker.score(image_scores)      \n",
    "    # result update \n",
    "    img_level.update(image_scores, labels.type(torch.int))\n",
    "    pix_level.update(score_map, gts.type(torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'auroc': 0.6305986696230598, 'average_precision': 0.6627197968950415},\n",
       " {'auroc': 0.9653490618530766, 'average_precision': 0.12091722784310494})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_level.compute(), pix_level.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
